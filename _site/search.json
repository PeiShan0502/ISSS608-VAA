[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to my learning journey of ISSS608 Visual Analytics & Applications (VAA)\nin Singapore Management University (SMU), semester AY2023-24 April term!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello! I’m Kwok Pei Shan, studying at the Singapore Management University (SMU) Master of IT in Business (MITB) programme. This site is created using Quarto and published on Netlify, for the course ISSS608 Visual Analytics & Applications which is taught by Dr. Kam Tin Seong :)\nI hope you enjoy your time here haha :)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "basic principles and essential components of ggplot2\nplot statistical graphics based on the principle of Layered Grammar of Graphics\napply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "basic principles and essential components of ggplot2\nplot statistical graphics based on the principle of Layered Grammar of Graphics\napply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Getting started",
    "text": "Getting started\n\nInstall and load required libraries\nBefore we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\n\npacman::p_load(tidyverse)\n\n\n\nImporting data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\", show_col_types = FALSE)\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Introducing ggplot",
    "text": "Introducing ggplot\nggplot2 is an R package for declaratively creating data-driven graphics based on The Grammar of Graphics.\nIt is also part of the tidyverse family specially designed for visual exploration and communication. For more detail, visit ggplot2 link.\n\nR Graphics VS ggplot\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\nR Graphics:\n\nhist(exam_data$MATHS)\n\n\n\n\nggplot2:\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\nIf the code chunk is relatively simple if R Graphics is used, then why is ggplot2 recommended?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\n\nA Layered Grammar of Graphics\nggplot2 is an implementation of the Grammar of Graphics.\nThe seven grammars of ggplot2 are:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Essential Grammatical Elements in ggplot2: data",
    "text": "Essential Grammatical Elements in ggplot2: data\n\nggplot(data=exam_data)\n\n\n\n\nObservations:\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\nObservation: ggplot includes the x-axis and the axis label."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Essential Grammatical Elements in ggplot2: geom",
    "text": "Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\ngeom_col\ngeom_boxplot\ngeom_density\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\nGeometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\nGeometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\nNote that the above y scale is not very useful, in fact it is very misleading.\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\nGeometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNote that the default bin is 30.\n\n\nModifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\nModifying a geometric object by changing aes()\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\nGeometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot:\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           fill = GENDER)) +\n  geom_density()\n\n\n\n\n\n\nGeometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot:\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\nGeometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot:\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\nGeometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\ngeom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Essential Grammatical Elements in ggplot2: stat",
    "text": "Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\nWorking with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\nWorking with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\nWorking with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\nAdding a best fit curve on a scatterplot?\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()  \n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Essential Grammatical Elements in ggplot2: Facets",
    "text": "Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\nWorking with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\nfacet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\n- [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out)\n[`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped.\n[`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\n[`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n\nWorking with Coordinate\nBy default, the bar chart of ggplot2 is in vertical form:\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the vertical bar chart into horizontal bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\nChanging the y- and x-axis range\nThe scatter plot below is slightly misleading because the y-axis and x-axis range are not equal:\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100:\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Essential Grammatical Elements in ggplot2: themes",
    "text": "Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of themes can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\nWorking with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "Notes:\nwhat’s the difference between code block and code chunk?"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1",
    "section": "Loading R packages",
    "text": "Loading R packages\nIn the code chunk below, p_load() of pacman package is used to load tidyverse family of packages.\nNote: If it’s used only once - instead of loading the whole pacman package, we can do this instead to consume less resources:\n\npacman::p_load(tidyverse)\n\n# Advantage of using p_load:\n# you can load multiple packages in one line!\n\nInstead of using p_load, you can also do this:\n\nlibrary(tidyverse)\n#library(...)\n\n# But by doing this, have to create a new line for each package that I need to load."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-data",
    "title": "In-class Exercise 1",
    "section": "Loading Data",
    "text": "Loading Data\nMethod 1 (preferred method):\n\nrealis &lt;- read_csv(\"data/realis2019.csv\", show_col_types = FALSE)\n\n# read_csv is from tidyverse package\n# class(realis) is a tibblr dataframe\n# original column names will be retained.\n\nMethod 2:\n\nrealis.csv &lt;- \n  read.csv(\"data/realis2019.csv\")\n\n# read.csv is from Base R package\n# class(realis.csv) is a dataframe.\n# column names will be affected (e.g. spaces will be replaced with dots)\n\nAdvantage of using R over Python is that R already has base statistical packages, e.g., can just use hist() to plot histogram using the Base R package.\nThe code chunk below uses ggplot package to plot histogram:\n\nggplot(data = realis,\n       aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "In this chapter, we will use several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, we will:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "In this chapter, we will use several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, we will:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Getting started",
    "text": "Getting started\n\n2.2.1 Installing and loading the required libraries\nIn this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(tidyverse, ggrepel, ggthemes, hrbrthemes, patchwork)\n\n\n\nImporting data\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\nRecall: we use read_csv() so that the output will be a tibble data frame (which is easier to work with because the column names are retained!)\n\nexam_data &lt;- read_csv('data/Exam_data.csv', show_col_types = FALSE)\n\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Beyond ggplot2 Annotation: ggrepel",
    "text": "Beyond ggplot2 Annotation: ggrepel\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nNote to self: find out how to do panel tabset here\n\n\nggplot(data=exam_data,\n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5) +\n  geom_label(aes(label=ID),\n             hjust = 0.5,\n             vjust = -0.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle('English scores versus Maths scores for Primary 3')\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as shown in the plot above.\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\nWorking with ggrepel\nUsing geom_label_repel\n\nggplot(data = exam_data,\n       aes(x=MATHS,\n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  geom_label_repel(aes(label=ID),\n                   fontface='bold') +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle('English scores vs Maths scores for Primary 3')\n\n\n\n\nCompare with geom_text_repel()\n\nggplot(data = exam_data,\n       aes(x=MATHS,\n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  geom_text_repel(aes(label=ID),\n                   fontface='bold') +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle('English scores vs Maths scores for Primary 3')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Beyond ggplot2 Themes",
    "text": "Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nggplot(data = exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary = 100,\n                 color='grey25',\n                 fill='grey90') +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\nRefer to this link to learn more about ggplot2 Themes.\n\nWorking with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\nWorking with hrbthemes package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed and the fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"N\")\n\n\n\n\nFrom the code above:\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Beyond Single Graph",
    "text": "Beyond Single Graph\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions that provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs.\nFirst, let us create three statistical graphics by using the code chunk below.\n\n#Plot 1: Distribution of Maths scores\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np1\n\n\n\n\n\n#Plot 2: Distribution of English scores\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np2\n\n\n\n\nLastly, we will draw a scatterplot for English score versus Maths score by as shown below:\n\n# Plot 3: English scores vs Maths scores\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\np3\n\n\n\n\n\nCreating Composite Graphics: pathwork methods\nThere are several ggplot2 extension functions that support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package.\nIn this section, we are going to use a ggplot2 extension called patchwork which is\n\nspecially designed for combining separate ggplot2 graphs into a single figure\n\n.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\nCombining two ggplot2 graphs\nThe figures below shows a composite of two histograms created using the patchwork package:\n\np1 + p2\n\n\n\n\n\n\nCombining three ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“|” operator to place the plots beside each other,\n“/” operator to stack two ggplot2 graphs,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3\n\n\n\n\nTo learn more about this, refer to Plot Assembly.\n\n\nCreating a composite figure with auto-tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\nOther examples which I tried for fun:\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = '1')\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'a')\n\n\n\n\n\n\nCreating figure with inset_element()\nBesides providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\nCreating a composite figure by using patchwork and ggthemes\nThe figure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()\n\n\n\n\n\nNote: how to adjust the axis title size and axis label size, so that the plots appear nicely…?\n\nTrying callout tip:\n```{::: {.callout-tip} ## Tip with Title\nThis is an example of a callout with a title. :::\n\n```{::: {.callout-tip title=\"Tip with Title\"}\nThis is a callout with a title.\n:::"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#learning-outcome",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "title": "In-class Exercise 2",
    "section": "Getting Started",
    "text": "Getting Started\n\nLoad packages\nIn this in-class exercise, the following R packages will be used:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially designed for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\n\npacman::p_load(tidyverse, ggdist, ggridges, colorspace, ggthemes)\n\n\n\nImport data\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and save it into a tibble data.frame.\n\nexam_df &lt;- read_csv('data/Exam_data.csv', show_col_types = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution",
    "title": "In-class Exercise 2",
    "section": "Visualising Distribution",
    "text": "Visualising Distribution\n\nHistogram\n\nggplot(data = exam_df,\n       aes(x=ENGLISH)) +\n  geom_histogram(bins=20,\n                 boundary = 100,\n                 color='grey25',\n                 fill='grey90') +\n  theme_gray() +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\n\n\nProbability density plot\nBuild a probability density plot of English score as shown below\n\nggplot(exam_df,\n       aes(x = ENGLISH)) +\n  geom_density(\n    color = \"#1696d2\",\n    adjust = .65,\n    alpha = .6\n  )\n\n\n\n\n\n\nAlternative design\n\n#code typed during class (incomplete)\nmedian_eng &lt;- median(exam_df$ENGLISH)\nmean_eng &lt;- mean(exam_df$ENGLISH)\nstd_eng &lt;- sd(exam_df$ENGLISH)\n\nggplot(exam_df,\n       aes(x = ENGLISH)) +\n  geom_density(\n    color = \"#1696d2\",\n    adjust = .65,\n    alpha = .6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_eng,\n                sd = std_eng),\n    col = \"grey30\",\n    size = .8) +\n  geom_vline(\n    aes(xintercept = mean_eng),\n    colour= \"#4d5887\", \n    linewidth = .6,\n    linetype = 'dashed') +\n  annotate(geom = \"text\",\n           x = mean_eng - 8,\n           y = 0.04,\n           label = paste0(\"Mean ENGLISH: \",\n                          round(mean_eng), 2)),\n           color = \"#4d5887\") +\n  geom_vline(\n    aes(xintercept= median_eng),\n  )\n  )\n    \n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-with-ridgeline-plot",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-with-ridgeline-plot",
    "title": "In-class Exercise 2",
    "section": "Visualising Distribution with Ridgeline Plot",
    "text": "Visualising Distribution with Ridgeline Plot\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\nPlotting ridgeline graph: ggridges method\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nggplot(exam_df, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\nVarying fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nggplot(exam_df, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\nMapping the probabilities directly onto colour\nBesides providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nThe figure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nggplot(exam_df,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n#It is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\nRidgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nggplot(exam_df,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam_df,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-with-raincloud-plot",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-with-raincloud-plot",
    "title": "In-class Exercise 2",
    "section": "Visualising Distribution with Raincloud Plot",
    "text": "Visualising Distribution with Raincloud Plot\nRaincloud Plot is a data visualisation technique that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\nPlotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n#We remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\nAdding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\nAdding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\nFinishing touch\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "",
    "text": "There are two major residential property markets in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\nIn this exercise, we will prepare 2-3 data visualisations to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#context",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#context",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "",
    "text": "There are two major residential property markets in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\nIn this exercise, we will prepare 2-3 data visualisations to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstall and load required libraries\nIn this exercise, the following R packages will be used:\n\ntidyverse: an R package that assists with data import, data preparation and wrangling.\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe code chunk below will be used to check if these packages have been installed and also load them onto the working R environment:\n\npacman::p_load(tidyverse, ggrepel, ggthemes, hrbrthemes, patchwork)\n\n\n\nImport Data\nAs we are looking at the 1st quarter of 2024, we import the transaction data for 1 January 2024 to 31 March 2024, using read_csv() of readr package. readr is one of the packages within the tidyverse package.\n\nresidential2024Q1 &lt;- read_csv('data/ResidentialTransaction20240414220633.csv', show_col_types = FALSE)\n\nWe also import the transaction data in 2023, to compare with the 1st quarter of 2024:\n\nresidential2023Q1 &lt;- read_csv('data/ResidentialTransaction20240308160536.csv', show_col_types = FALSE)\nresidential2023Q2 &lt;- read_csv('data/ResidentialTransaction20240308160736.csv', show_col_types = FALSE)\nresidential2023Q3 &lt;- read_csv('data/ResidentialTransaction20240308161009.csv', show_col_types = FALSE)\nresidential2023Q4 &lt;- read_csv('data/ResidentialTransaction20240308161109.csv', show_col_types = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-visualisations",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-visualisations",
    "title": "Take-home Exercise 1",
    "section": "Data Visualisations",
    "text": "Data Visualisations\n\n1. Within private purchases, count no. of property (frequency on y-axis) and transaction price (x-axis) –&gt; Histogram. overlap with HDB purchases.\nKIV ideas\n1. Average Transacted Price and Purchaser Address Indicator (HDB/Private/N.A.) use bar chart- KIV\n2. Within private purchases, compare transacted prices by property type - KIV"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-visualizations",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-visualizations",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "Data Visualizations",
    "text": "Data Visualizations\n\nCompare Transacted Price by Type of Sale\n\nComparing Transacted Price by Type of Sale, in 2024 Q1\n\n\nggplot(data=residential2024Q1, \n       aes(y = `Transacted Price ($)`,       \n           x= `Type of Sale`)) +    \n    scale_y_continuous(labels = scales::comma) +\n  geom_boxplot()            \n\n\n\n\nThe above chart does not look very useful as the box plots look very squished due to a large range in transacted price.\nWe remove two outliers, where Transacted price is at $39.5mil and $26.5mil:\n\nresidential2024Q1_no_outlier &lt;- \n  residential2024Q1[residential2024Q1$`Transacted Price ($)` &lt; 26500000,]\n\nand plot the box plots again:\n\np1 &lt;- ggplot(data=residential2024Q1_no_outlier, \n       aes(y = `Transacted Price ($)`,       \n           x= `Type of Sale`)) +    \n    scale_y_continuous(labels = scales::comma) +\n  geom_boxplot() +\n  ggtitle(\"Transacted Prices in 2024 Q1\")\n\np1\n\n\n\n\nThe above data visualisation shows that in 2024 Q1, the median transacted price for resale is slightly lower than that of new sale. This is surprising considering that resale is usually deemed to be more expensive. However, the range of prices for resale is also larger as compared to new sale or sub sale, as shown by its larger interquartile range (IQR).\nWe repeat the same steps for 2023 Q1 transaction data, to see if there is any difference with 2024 Q1:\n\nComparing Transacted Price by Type of Sale, in 2023 Q1\n\n\nggplot(data=residential2023Q1, \n       aes(y = `Transacted Price ($)`,       \n           x= `Type of Sale`)) +    \n    scale_y_continuous(labels = scales::comma) +\n  geom_boxplot()  \n\n\n\n\nRemoving the outlier (where Transacted Price &gt; $30mil) and plotting the box plots again:\n\nresidential2023Q1_no_outlier &lt;- \n  residential2023Q1[residential2023Q1$`Transacted Price ($)` &lt; 30000000,]\n\n\np2 &lt;- ggplot(data=residential2023Q1_no_outlier, \n       aes(y = `Transacted Price ($)`,       \n           x= `Type of Sale`)) +    \n    scale_y_continuous(labels = scales::comma) +\n  geom_boxplot() +\n  ggtitle(\"Transacted Prices in 2023 Q1\")\n\np2\n\n\n\n\nSimilar to 2024 Q1, the above chart shows that the median transacted price is lower for resale (as compared to new sale). However, the interquartile range of transacted prices of resale and new sale are similar, and the interquartile range of transacted prices for sub sale is much smaller this time.\nIt would be useful to compare these plots side-by-side for comparison of the same quarter in different years. We can use the patchwork package to do so:\n\np1 | p2\n\n\n\n\nPotential improvements to the above composite plot:\n\nSynchronise the Type of Sale axis for both 2024 Q1 and 2023 Q1\nSynchronise the Transacted Price ($) axis for both 2024 Q1 and 2023 Q1, for better comparison between the two plots.\n\n\n\nCompare No. of Sales by Quarter\nWe would like to see whether there is any difference in the number of transactions in each quarter. We can visualise this using a bar chart.\n\np3 &lt;- ggplot(data=residential2023, \n       aes(x=Quarter)) +\n  geom_bar() +\n  ggtitle('No. of Transactions in each Quarter (2023)') +\n  labs(y = 'No. of Transactions')\n\np3\n\n\n\n\nThe above bar chart shows that in 2023, there were more transactions taking place in Q2 and Q3 (i.e., April to September), compared to Q1 (January to March) and Q4 (October to December). A possible reason why there are fewer transactions in Q1 may be because of the Chinese New Year celebrations in Singapore, and a possible reason why there are fewer transactions in Q4 may be because it’s during the school holidays where families tend to go for overseas vacations instead of buying property.\nWe also compare 2023 Q1 sale with 2024 Q1 sale:\n\nresidentialQ1 &lt;- rbind(residential2023Q1, residential2024Q1)\n\n\np4 &lt;- ggplot(data=residentialQ1, \n       aes(x=Year)) +\n  geom_bar() +\n  ggtitle('Comparing Q1 Sales') +\n  labs(y = 'No. of Transactions')\n\np4\n\n\n\n\nThe above plot shows that the number of transactions in 2024 Q1 is almost the same than the number of transactions in 2023 Q1 (only slightly higher).\nWe put both bar charts together in a composite plot:\n\np3 + p4\n\n\n\n\n\n\nCompare Transacted Price By Property Type\nFirst, we combine all the data into one combined dataset:\n\nresidential &lt;- rbind(residential2023Q1, residential2023Q2, residential2023Q3, residential2023Q4, residential2024Q1)\n\nThen we plot a box plot of transacted prices by property type:\n\nggplot(data=residential, \n       aes(y = `Transacted Price ($)`,       \n           x= `Property Type`)) +    \n    scale_y_continuous(labels = scales::comma) +\n  geom_boxplot() +\n  ggtitle(\"Transacted Prices by Property Type\")\n\n\n\n\nRemoving data points which Transacted Price &gt; 100million, so that we can see the box plots better:\n\nresidential_no_outlier &lt;- \n  residential[residential$`Transacted Price ($)` &lt; 100000000,]\n\n\nggplot(data=residential_no_outlier, \n       aes(y = `Transacted Price ($)`,       \n           x= `Property Type`)) +    \n    scale_y_continuous(labels = scales::comma) +\n  geom_boxplot() +\n  ggtitle(\"Transacted Prices by Property Type (&lt; $100mil)\")\n\n\n\n\nThe above box plot shows that the property type with the highest median price is Detached House. It also has the largest interquartile range."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-and-conclusion",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-and-conclusion",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "Summary and Conclusion",
    "text": "Summary and Conclusion\n\nThe median price for resale property is surprisingly, lower than that of new sale. However, the prices of resale property also have higher variability.\nThere are more sales in Q2 and Q3, as compared to Q1 or Q4.\nThe property type with the highest median price is Detached House."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#key-references",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#key-references",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "Key References",
    "text": "Key References\nR for Visual Analytics\nURA Data Dictionary"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nAdd “Quarter” column\nFor our analysis in the later part of this exercise, we need to add new columns “Year” and “Quarter” to indicate which quarter of the year each transaction took place in.\nFor 2024 Q1 data:\n\nresidential2024Q1 &lt;- cbind(residential2024Q1, Quarter = 'Q1')\n\nFor each quarter of 2023 data:\n\nresidential2023Q1 &lt;- cbind(residential2023Q1, Quarter = 'Q1')\nresidential2023Q2 &lt;- cbind(residential2023Q2, Quarter = 'Q2')\nresidential2023Q3 &lt;- cbind(residential2023Q3, Quarter = 'Q3')\nresidential2023Q4 &lt;- cbind(residential2023Q4, Quarter = 'Q4')\n\nCombine all 4 quarters of 2023, to get a dataset with all transactions in 2023:\n\nresidential2023 &lt;- rbind(residential2023Q1, residential2023Q2, residential2023Q3, residential2023Q4)\n\n\n\nCheck for duplicates\nThe code chunk below shows that there are no duplicates in the 2024 Q1 transaction data:\n\nresidential2024Q1[duplicated(residential2024Q1),]\n\n [1] Project Name                Transacted Price ($)       \n [3] Area (SQFT)                 Unit Price ($ PSF)         \n [5] Sale Date                   Address                    \n [7] Type of Sale                Type of Area               \n [9] Area (SQM)                  Unit Price ($ PSM)         \n[11] Nett Price($)               Property Type              \n[13] Number of Units             Tenure                     \n[15] Completion Date             Purchaser Address Indicator\n[17] Postal Code                 Postal District            \n[19] Postal Sector               Planning Region            \n[21] Planning Area               Quarter                    \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nSimilarly, there are no duplicates in the 2023 transaction data:\n\nresidential2023[duplicated(residential2023),]\n\n [1] Project Name                Transacted Price ($)       \n [3] Area (SQFT)                 Unit Price ($ PSF)         \n [5] Sale Date                   Address                    \n [7] Type of Sale                Type of Area               \n [9] Area (SQM)                  Unit Price ($ PSM)         \n[11] Nett Price($)               Property Type              \n[13] Number of Units             Tenure                     \n[15] Completion Date             Purchaser Address Indicator\n[17] Postal Code                 Postal District            \n[19] Postal Sector               Planning Region            \n[21] Planning Area               Quarter                    \n&lt;0 rows&gt; (or 0-length row.names)\n\n\n\n\nCheck for missing values\nThe colSums() function in the base package is used to check for missing values. The output of the code chunk below shows there are no missing values in the 2024 transaction data.\n\ncolSums(is.na(residential2024Q1))\n\n               Project Name        Transacted Price ($) \n                          0                           0 \n                Area (SQFT)          Unit Price ($ PSF) \n                          0                           0 \n                  Sale Date                     Address \n                          0                           0 \n               Type of Sale                Type of Area \n                          0                           0 \n                 Area (SQM)          Unit Price ($ PSM) \n                          0                           0 \n              Nett Price($)               Property Type \n                          0                           0 \n            Number of Units                      Tenure \n                          0                           0 \n            Completion Date Purchaser Address Indicator \n                          0                           0 \n                Postal Code             Postal District \n                          0                           0 \n              Postal Sector             Planning Region \n                          0                           0 \n              Planning Area                     Quarter \n                          0                           0 \n\n\nHowever, there are 6 missing values in the Area (SQM) column in the 2023 transaction data. As this makes up only 0.0274% of the 2023 transaction data, we will remove them from the subsequent analysis. The na.omit() function in the stats package is used to remove them from residential2023, which now has 21,898 observations and 21 variables. A confirmatory check is then made with the colSums() function in the base package.\n\ncolSums(is.na(residential2023))\n\n               Project Name        Transacted Price ($) \n                          0                           0 \n                Area (SQFT)          Unit Price ($ PSF) \n                          0                           0 \n                  Sale Date                     Address \n                          0                           0 \n               Type of Sale                Type of Area \n                          0                           0 \n                 Area (SQM)          Unit Price ($ PSM) \n                          6                           0 \n              Nett Price($)               Property Type \n                          0                           0 \n            Number of Units                      Tenure \n                          0                           0 \n            Completion Date Purchaser Address Indicator \n                          0                           0 \n                Postal Code             Postal District \n                          0                           0 \n              Postal Sector             Planning Region \n                          0                           0 \n              Planning Area                     Quarter \n                          0                           0 \n\n\n\nresidential2023 = residential2023 %&gt;%\n  na.omit()\n\n\ncolSums(is.na(residential2023))\n\n               Project Name        Transacted Price ($) \n                          0                           0 \n                Area (SQFT)          Unit Price ($ PSF) \n                          0                           0 \n                  Sale Date                     Address \n                          0                           0 \n               Type of Sale                Type of Area \n                          0                           0 \n                 Area (SQM)          Unit Price ($ PSM) \n                          0                           0 \n              Nett Price($)               Property Type \n                          0                           0 \n            Number of Units                      Tenure \n                          0                           0 \n            Completion Date Purchaser Address Indicator \n                          0                           0 \n                Postal Code             Postal District \n                          0                           0 \n              Postal Sector             Planning Region \n                          0                           0 \n              Planning Area                     Quarter \n                          0                           0 \n\n\n\n# check that missing values have been removed.\nglimpse(residential2023)\n\nRows: 21,898\nColumns: 22\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n$ Quarter                       &lt;chr&gt; \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\"…\n\n\n\n\nCheck data type\nA glimpse into the transaction data in 2024 shows that the Sale Date column is currently in the character data type instead of the Date data type:\n\nglimpse(residential2024Q1)\n\nRows: 4,902\nColumns: 22\n$ `Project Name`                &lt;chr&gt; \"THE LANDMARK\", \"POLLEN COLLECTION\", \"SK…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2726888, 3850000, 2346000, 2190000, 1954…\n$ `Area (SQFT)`                 &lt;dbl&gt; 1076.40, 1808.35, 1087.16, 807.30, 796.5…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2533, 2129, 2158, 2713, 2453, 2577, 838,…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2024\", \"01 Jan 2024\", \"01 Jan 20…\n$ Address                       &lt;chr&gt; \"173 CHIN SWEE ROAD #22-11\", \"34 POLLEN …\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Land\", \"Strata\", \"Strata\", \"S…\n$ `Area (SQM)`                  &lt;dbl&gt; 100.0, 168.0, 101.0, 75.0, 74.0, 123.0, …\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 27269, 22917, 23228, 29200, 26405, 27741…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Terrace House\", \"Apartme…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 28/08/2020\", \"99 yrs from 0…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"Private\", \"N.A\", \"HDB\", \"N.A\", \"Private…\n$ `Postal Code`                 &lt;chr&gt; \"169878\", \"807233\", \"469657\", \"118992\", …\n$ `Postal District`             &lt;chr&gt; \"03\", \"28\", \"16\", \"05\", \"21\", \"21\", \"28\"…\n$ `Postal Sector`               &lt;chr&gt; \"16\", \"80\", \"46\", \"11\", \"59\", \"58\", \"79\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"North East Region\", \"…\n$ `Planning Area`               &lt;chr&gt; \"Outram\", \"Serangoon\", \"Bedok\", \"Queenst…\n$ Quarter                       &lt;chr&gt; \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\"…\n\n\nWe convert it into Date data type using the following code:\n\nresidential2024Q1$`Sale Date` &lt;- \n  as.Date(parse_date_time(residential2024Q1$`Sale Date`, orders = c(\"%d %b %Y\")))\n\n\n#Alternative method to check data type of each variable\nstr(residential2024Q1)\n\n'data.frame':   4902 obs. of  22 variables:\n $ Project Name               : chr  \"THE LANDMARK\" \"POLLEN COLLECTION\" \"SKY EDEN@BEDOK\" \"TERRA HILL\" ...\n $ Transacted Price ($)       : num  2726888 3850000 2346000 2190000 1954000 ...\n $ Area (SQFT)                : num  1076 1808 1087 807 797 ...\n $ Unit Price ($ PSF)         : num  2533 2129 2158 2713 2453 ...\n $ Sale Date                  : Date, format: \"2024-01-01\" \"2024-01-01\" ...\n $ Address                    : chr  \"173 CHIN SWEE ROAD #22-11\" \"34 POLLEN PLACE\" \"1 BEDOK CENTRAL #09-10\" \"18A YEW SIANG ROAD #03-12\" ...\n $ Type of Sale               : chr  \"New Sale\" \"New Sale\" \"New Sale\" \"New Sale\" ...\n $ Type of Area               : chr  \"Strata\" \"Land\" \"Strata\" \"Strata\" ...\n $ Area (SQM)                 : num  100 168 101 75 74 ...\n $ Unit Price ($ PSM)         : num  27269 22917 23228 29200 26405 ...\n $ Nett Price($)              : chr  \"-\" \"-\" \"-\" \"-\" ...\n $ Property Type              : chr  \"Condominium\" \"Terrace House\" \"Apartment\" \"Apartment\" ...\n $ Number of Units            : num  1 1 1 1 1 1 1 1 1 1 ...\n $ Tenure                     : chr  \"99 yrs from 28/08/2020\" \"99 yrs from 09/12/2019\" \"99 yrs from 05/01/2022\" \"Freehold\" ...\n $ Completion Date            : chr  \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" ...\n $ Purchaser Address Indicator: chr  \"Private\" \"N.A\" \"HDB\" \"N.A\" ...\n $ Postal Code                : chr  \"169878\" \"807233\" \"469657\" \"118992\" ...\n $ Postal District            : chr  \"03\" \"28\" \"16\" \"05\" ...\n $ Postal Sector              : chr  \"16\" \"80\" \"46\" \"11\" ...\n $ Planning Region            : chr  \"Central Region\" \"North East Region\" \"East Region\" \"Central Region\" ...\n $ Planning Area              : chr  \"Outram\" \"Serangoon\" \"Bedok\" \"Queenstown\" ...\n $ Quarter                    : chr  \"Q1\" \"Q1\" \"Q1\" \"Q1\" ...\n\n\nSimilarly, we convert the data type of “Sale Date” in residential2023 from character data type to Date data type:\n\nresidential2023$`Sale Date` &lt;- \n  as.Date(parse_date_time(residential2023$`Sale Date`, orders = c(\"%d %b %Y\")))\n\n\nresidential2023Q1$`Sale Date` &lt;- \n  as.Date(parse_date_time(residential2023Q1$`Sale Date`, orders = c(\"%d %b %Y\")))\n\nresidential2023Q2$`Sale Date` &lt;- \n  as.Date(parse_date_time(residential2023Q2$`Sale Date`, orders = c(\"%d %b %Y\")))\n\nresidential2023Q3$`Sale Date` &lt;- \n  as.Date(parse_date_time(residential2023Q3$`Sale Date`, orders = c(\"%d %b %Y\")))\n\nresidential2023Q4$`Sale Date` &lt;- \n  as.Date(parse_date_time(residential2023Q4$`Sale Date`, orders = c(\"%d %b %Y\")))\n\n\n\nAdd “Year” column\nFor our analysis in the later part of this exercise, we also add a new column “Year” to indicate which year each transaction took place in.\n\nresidential2024Q1 &lt;- cbind(residential2024Q1, \n                           Year = as.character(year(residential2024Q1$`Sale Date`)))\n\n\nresidential2023 &lt;- cbind(residential2023, \n                           Year = as.character(year(residential2023$`Sale Date`)))\n\n\nresidential2023Q1 &lt;- cbind(residential2023Q1, \n                           Year = as.character(year(residential2023Q1$`Sale Date`)))\n\nresidential2023Q2 &lt;- cbind(residential2023Q2, \n                           Year = as.character(year(residential2023Q2$`Sale Date`)))\n\nresidential2023Q3 &lt;- cbind(residential2023Q3, \n                           Year = as.character(year(residential2023Q3$`Sale Date`)))\n\nresidential2023Q4 &lt;- cbind(residential2023Q4, \n                           Year = as.character(year(residential2023Q4$`Sale Date`)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#learning-outcome",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#getting-started",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "Getting Started",
    "text": "Getting Started\nFirst, we will install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#importing-data",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "Importing Data",
    "text": "Importing Data\nread_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - ggiraph methods",
    "text": "Interactive Data Visualisation - ggiraph methods\nggiraph  is an html widget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it is used within a Shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detailed explanation.\n\nTooltip effect with tooltip aesthetic\nBelow, we plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\nFirst, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\nDisplaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7. By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\nCustomising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\nNotice that the background colour of the tooltip is white and the font colour is black. Refer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\nDisplaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\nHover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over:\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\n\nStyling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\nCombining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\nClick effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\nCoordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below:\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mousing over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - plotly methods!",
    "text": "Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\nCreating an interactive scatter plot: plot_ly() method\nThe code chunk below shows an example of a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\nWorking with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\nIt’s Interactive - try Clicking on the colour symbol at the legend.\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nCoordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nIt’s interactive - Click on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - crosstalk methods!",
    "text": "Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nInteractive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\nLinked brushing: crosstalk method\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#reference",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "Reference",
    "text": "Reference\n\nggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\nplotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisations by using gganimate and plotly R packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#overview",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisations by using gganimate and plotly R packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#getting-started",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "Getting Started",
    "text": "Getting Started\n\nLoading the R packages\nFirst, we check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\nImporting the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWe import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "Animated Data Visualisation: gganimate methods",
    "text": "Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nBuilding a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\nBuilding the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "Animated Data Visualisation: plotly",
    "text": "Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\nBuilding an animated bubble plot: ggplotly() method\nIn this sub-section, we will learn how to create an animated bubble plot by using ggplotly() method.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\nBuilding an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#reference",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "Reference",
    "text": "Reference\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 1 Part 2: DataVis Makeover",
    "section": "",
    "text": "In this take-home exercise, we will select one data visualisation and critic it in terms of clarity and aesthetics. We will then remake the data visualisation by using ggplot2, ggplot2 extensions and tidyverse packages."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "(continue from Hands-on Ex4a)\n\n\n\npacman::p_load(tidyverse, ggstatsplot) \n\ntidyr, dplyr, ggplot2, readr is all part of tidyverse package.\n\n\n\n\nexam &lt;- read_csv('data/Exam_data.csv', show_col_types = FALSE)\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"parametric\", \n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English scores\"\n)\n\n\n\n#student t-test\n#blue dashed line represent Mean\n\n\n#type = \"non-parametric\"\n\nset.seed(1234)\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"np\", \n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English scores\"\n)\n\np\n\n\n\n#Wilcoxon test\n#blue dashed line represents Median\n\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 12\n  statistic  p.value method                    alternative effectsize       \n      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                     &lt;chr&gt;       &lt;chr&gt;            \n1     38743 3.43e-16 Wilcoxon signed rank test two.sided   r (rank biserial)\n  estimate conf.level conf.low conf.high conf.method n.obs expression\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt; &lt;list&gt;    \n1    0.528       0.95    0.430     0.613 normal        322 &lt;language&gt;\n\n$caption_data\nNULL\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\n\n\ntype = \"robust\"\n\nuses bootstrap method to calculate test statistic\nblue dashed line: shows trimmed because it removes outliers\n\ntype = \"bayes\"\n\nblue dashed line: MAP - using simulated values and not raw data\n\ntry putting normal.curve = TRUE (default is FALSE)\n\n#type = \"bayes\"\n#normal.curve = TRUE with line width = 0.5\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\", \n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = TRUE,\n  normal.curve.args = list(linewidth = 0.5),\n  xlab = \"English scores\"\n)\n\n\n\n\n\nggdotplotstats(\n  data = exam,\n  x = ENGLISH,\n  y = CLASS,\n  title = \"\",\n  xlab = \"\"\n)\n\n\n\n\nDoes sorting based on English scores, and adds in average line\nThe above dot plot shows that class 3D actually did better than class 3C in English.\n\nexam_long &lt;- exam %&gt;%\n  pivot_longer(\n    cols = ENGLISH:SCIENCE,\n    names_to = \"SUBJECT\",\n    values_to = \"SCORES\") %&gt;%\n  filter(CLASS == \"3A\")\n\n\nggwithinstats(\n  data = filter(exam_long,\n                SUBJECT %in%\n                  c(\"MATHS\", \"SCIENCE\")),\n  x = SUBJECT,\n  y = SCORES,\n  type = \"p\"\n)\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE, \n  label.var = ID,\n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90,\n)\n\n\n\n#try marginal = FALSE\n#label.var: means label.variable\n#pick up student ID of students where ENGLISH &gt; 90 and MATHS &gt; 90. \n#using Pearson correlation because both variables are continuous. \n#student t-test since type = parametric (using default value since it's not specified)\n\nFocus for today: performance package of easystats"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#install-r-packages",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#install-r-packages",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggstatsplot) \n\ntidyr, dplyr, ggplot2, readr is all part of tidyverse package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#load-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#load-data",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "exam &lt;- read_csv('data/Exam_data.csv', show_col_types = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualisations-using-ggstatsplot",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualisations-using-ggstatsplot",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "set.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"parametric\", \n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English scores\"\n)\n\n\n\n#student t-test\n#blue dashed line represent Mean\n\n\n#type = \"non-parametric\"\n\nset.seed(1234)\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"np\", \n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English scores\"\n)\n\np\n\n\n\n#Wilcoxon test\n#blue dashed line represents Median\n\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 12\n  statistic  p.value method                    alternative effectsize       \n      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                     &lt;chr&gt;       &lt;chr&gt;            \n1     38743 3.43e-16 Wilcoxon signed rank test two.sided   r (rank biserial)\n  estimate conf.level conf.low conf.high conf.method n.obs expression\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt; &lt;list&gt;    \n1    0.528       0.95    0.430     0.613 normal        322 &lt;language&gt;\n\n$caption_data\nNULL\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\n\n\ntype = \"robust\"\n\nuses bootstrap method to calculate test statistic\nblue dashed line: shows trimmed because it removes outliers\n\ntype = \"bayes\"\n\nblue dashed line: MAP - using simulated values and not raw data\n\ntry putting normal.curve = TRUE (default is FALSE)\n\n#type = \"bayes\"\n#normal.curve = TRUE with line width = 0.5\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\", \n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = TRUE,\n  normal.curve.args = list(linewidth = 0.5),\n  xlab = \"English scores\"\n)\n\n\n\n\n\nggdotplotstats(\n  data = exam,\n  x = ENGLISH,\n  y = CLASS,\n  title = \"\",\n  xlab = \"\"\n)\n\n\n\n\nDoes sorting based on English scores, and adds in average line\nThe above dot plot shows that class 3D actually did better than class 3C in English.\n\nexam_long &lt;- exam %&gt;%\n  pivot_longer(\n    cols = ENGLISH:SCIENCE,\n    names_to = \"SUBJECT\",\n    values_to = \"SCORES\") %&gt;%\n  filter(CLASS == \"3A\")\n\n\nggwithinstats(\n  data = filter(exam_long,\n                SUBJECT %in%\n                  c(\"MATHS\", \"SCIENCE\")),\n  x = SUBJECT,\n  y = SCORES,\n  type = \"p\"\n)\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE, \n  label.var = ID,\n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90,\n)\n\n\n\n#try marginal = FALSE\n#label.var: means label.variable\n#pick up student ID of students where ENGLISH &gt; 90 and MATHS &gt; 90. \n#using Pearson correlation because both variables are continuous. \n#student t-test since type = parametric (using default value since it's not specified)\n\nFocus for today: performance package of easystats"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters",
    "title": "In-class Exercise 4",
    "section": "Visualising Regression Parameters",
    "text": "Visualising Regression Parameters\n\nt &lt;- parameters(model1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#introduction",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#introduction",
    "title": "Take-home Exercise 1 Part 2: DataVis Makeover",
    "section": "",
    "text": "In this take-home exercise, we will select one data visualisation and critic it in terms of clarity and aesthetics. We will then remake the data visualisation by using ggplot2, ggplot2 extensions and tidyverse packages."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "title": "Take-home Exercise 1 Part 2: DataVis Makeover",
    "section": "Getting Started",
    "text": "Getting Started\n\nLoad R packages\nFirst, we install and load the following R packages:\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               gganimate, ggrepel,\n               patchwork, colorspace,\n               tidyverse)\n\n\n\nImport Data\nThen we import the necessary data:\n\nq1_23 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\nq2_23 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\nq3_23 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\nq4_23 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\nq1_24 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\n\nThe code chunk below combines all the data from 2023 and 2024 Q1 into one data set:\n\nprivate_property_data &lt;- rbind(q1_23, q2_23, q3_23, q4_23, q1_24)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critic-data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critic-data-visualisation",
    "title": "Take-home Exercise 1 Part 2: DataVis Makeover",
    "section": "Critic Data Visualisation",
    "text": "Critic Data Visualisation\nSubmission taken from: Distribution of Private Residential Market (1st quarter of 2023 - 1st quarter of 2024)\nThis is the original histogram:\n\nggplot(data=private_property_data, \n       aes(x= `Unit Price ($ PSM)`, \n           fill = `Property Type`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\nClarity:\n\nIt is clear because y-axis starts from 0, and the height of 2D columns are easy to gauge.\nStacked histogram makes it difficult to gauge the height of the columns for each property type, and hence it’s difficult to see the distribution of prices for each property type. For example, detached house and semi-detached house can hardly be seen in the histogram.\nY-axis label axis - it may not be clear to the viewer, that the count is actually referring to the no. of transactions.\n\nAesthetics:\n\nGood font selection.\nBut there are too many colours which can be visual sensory overload and distracting for the viewer."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#improvement-in-data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#improvement-in-data-visualisation",
    "title": "Take-home Exercise 1 Part 2: DataVis Makeover",
    "section": "Improvement in Data Visualisation",
    "text": "Improvement in Data Visualisation\n\nApartment, Condominium, and Terrace House\nThe code chunks below filter the combined data set to show only “Apartment” property type, and then plots a histogram to show the distribution of Unit Price ($ PSM) for Apartment:\n\napartment &lt;- filter(private_property_data, `Property Type` == 'Apartment')\n\napartment\n\n# A tibble: 10,772 × 21\n   `Project Name`      `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n   &lt;chr&gt;                                &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n 1 WHISTLER GRAND                      850000          441.                 1926\n 2 WILSHIRE RESIDENCES                1990000          753.                 2641\n 3 WILSHIRE RESIDENCES                1975000          743.                 2659\n 4 PARC CLEMATIS                      2735000         1464.                 1868\n 5 MOOI RESIDENCES                    3288888         1281.                 2568\n 6 THE URBANITE                       1470000         1173.                 1253\n 7 ESPIRA RESIDENCE                   1280000         1141.                 1122\n 8 THE SIERRA                         1715000         1033.                 1660\n 9 THE SAIL @ MARINA …                1588888          883.                 1800\n10 THOMSON THREE                       875000          495.                 1767\n# ℹ 10,762 more rows\n# ℹ 17 more variables: `Sale Date` &lt;chr&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\np1 &lt;- ggplot(data=apartment, \n       aes(x= `Unit Price ($ PSM)`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\",\n                 fill = \"grey\") +\n  ylab('No. of Transactions') +\n  ggtitle(\"Apartment\")\n\np1\n\n\n\n\nSimilarly, the code chunks below filter the combined data set to show only “Condominium” property type, and then plots a histogram to show the distribution of Unit Price ($ PSM) for Condominium:\n\ncondo &lt;- filter(private_property_data, `Property Type` == 'Condominium')\n\ncondo\n\n# A tibble: 10,643 × 21\n   `Project Name`      `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n   &lt;chr&gt;                                &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n 1 THE REEF AT KING'S…                2317000          883.                 2625\n 2 URBAN TREASURES                    1823500          883.                 2066\n 3 PARC BOTANNIA                      1280000          872.                 1468\n 4 AMBER PARK                         1888000          678.                 2784\n 5 THE GAZANIA                        1477000          635.                 2326\n 6 REFLECTIONS AT KEP…                2930000         1421.                 2062\n 7 PARC EMILY                         2000000         1001.                 1998\n 8 A TREASURE TROVE                   1060000          775.                 1368\n 9 THE SIXTH AVENUE R…                2250000          969.                 2323\n10 KEW GREEN                          2610000         3057.                  854\n# ℹ 10,633 more rows\n# ℹ 17 more variables: `Sale Date` &lt;chr&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\np2 &lt;- ggplot(data=condo, \n       aes(x= `Unit Price ($ PSM)`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\",\n                 fill = \"grey\") +\n  ylab('No. of Transactions') +\n  ggtitle(\"Condominium\")\n\np2\n\n\n\n\nSimilarly, the code chunks below filter the combined data set to show only “Terrace House” property type, and then plots a histogram to show the distribution of Unit Price ($ PSM) for Terrace House:\n\nterrace_house &lt;- filter(private_property_data, `Property Type` == 'Terrace House')\n\nterrace_house\n\n# A tibble: 1,100 × 21\n   `Project Name`      `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n   &lt;chr&gt;                                &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n 1 NANYANG PARK                       5870000         3323.                 1767\n 2 N.A.                               3260000         1555.                 2096\n 3 N.A.                               2800000         2292.                 1222\n 4 PEAKVILLE PARK                     3300000         1668.                 1978\n 5 HILLVIEW GARDEN ES…                3800000         2152.                 1766\n 6 LOYANG VILLAS                      2350000         1660.                 1416\n 7 KECHUBONG TERRACE                  3308000         1696.                 1950\n 8 N.A.                               6000888         1702.                 3526\n 9 GOLDEN HILL ESTATE                 5998000         3926.                 1528\n10 THOMSON GRAND                      3600000         5156.                  698\n# ℹ 1,090 more rows\n# ℹ 17 more variables: `Sale Date` &lt;chr&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\np3 &lt;- ggplot(data=terrace_house, \n       aes(x= `Unit Price ($ PSM)`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\",\n                 fill = \"grey\") +\n  ylab('No. of Transactions') +\n  ggtitle(\"Terrace House\")\n\np3\n\n\n\n\nSince we see that Apartment, Condominium and Terrace House all have the same range of Unit Price ($ PSM), we put them together to compare the distributions:\n\n((p1 / p2) / p3) +\n  plot_annotation(title = 'Property Prices, 2023 to 2024 Q1')\n\n\n\n\n\n\nDetached House and Semi-Detached House\nThe code chunks below filter the combined data set to show only “Detached House” property type, and then plots a histogram to show the distribution of Unit Price ($ PSM) for Detached House:\n\ndetached_house &lt;- filter(private_property_data, `Property Type` == 'Detached House')\n\ndetached_house\n\n# A tibble: 233 × 21\n   `Project Name`      `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n   &lt;chr&gt;                                &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n 1 CHANGI GROVE                       5600000         4585.                 1221\n 2 SEMBAWANG SPRINGS …                6580000         6518.                 1010\n 3 SERANGOON GARDEN E…                6000000         4312.                 1391\n 4 KIM LIN PARK                      15050000         4867.                 3092\n 5 N.A.                              11100000        10280.                 1080\n 6 N.A.                              55500000        25681.                 2161\n 7 EDEN PARK                         11000000         5225.                 2105\n 8 N.A.                              10200000        10640.                  959\n 9 GREEN HILL ESTATE                  7268000         5999.                 1212\n10 N.A.                              12800000         5293.                 2418\n# ℹ 223 more rows\n# ℹ 17 more variables: `Sale Date` &lt;chr&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\np4 &lt;- ggplot(data=detached_house, \n       aes(x= `Unit Price ($ PSM)`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\",\n                 fill = \"grey\") +\n  ylab('No. of Transactions') +\n  ggtitle(\"Detached House\")\n\np4\n\n\n\n\nSimilarly, the code chunks below filter the combined data set to show only “Semi-Detached House” property type, and then plots a histogram to show the distribution of Unit Price ($ PSM) for Semi-Detached House:\n\nsemi_detached &lt;- filter(private_property_data, `Property Type` == 'Semi-Detached House')\n\nsemi_detached\n\n# A tibble: 524 × 21\n   `Project Name`      `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n   &lt;chr&gt;                                &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n 1 PALMS @ SIXTH AVEN…                4950000         4521.                 1095\n 2 FRANKEL ESTATE                     6765000         3962.                 1707\n 3 N.A.                              12600000         5346.                 2357\n 4 SEMBAWANG STRAITS …                2500000         1690.                 1479\n 5 KINGSVILLE                         4750000         3412.                 1392\n 6 TAI KENG GARDENS                   4280000         3595.                 1190\n 7 SEA VIEW PARK                      6350000         3399.                 1868\n 8 N.A.                               3900000         2455.                 1588\n 9 CHIP HOCK GARDENS                 10500000         3148.                 3335\n10 N.A.                               5880000         3239.                 1815\n# ℹ 514 more rows\n# ℹ 17 more variables: `Sale Date` &lt;chr&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\np5 &lt;- ggplot(data=semi_detached, \n       aes(x= `Unit Price ($ PSM)`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\",\n                 fill = \"grey\") +\n  ylab('No. of Transactions') +\n  ggtitle(\"Semi-Detached House\")\n\np5\n\n\n\n\nAgain, since we see that both Detached House and Semi-Detached House have the same range of Unit Price ($ PSM), we put them together to compare the distributions:\n\n(p4 / p5) +\n  plot_annotation(title = 'Detached House and Semi-Detached House Property Prices, 2023 to 2024 Q1')\n\n\n\n\n\n\nExecutive Condominium\nThe code chunks below filter the combined data set to show only “Executive Condominium” property type, and then plots a histogram to show the distribution of Unit Price ($ PSM) for Executive Condominium:\n\nexec_condo &lt;- filter(private_property_data, `Property Type` == 'Executive Condominium')\n\nexec_condo\n\n# A tibble: 3,534 × 21\n   `Project Name`     `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n   &lt;chr&gt;                               &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n 1 NORTH GAIA                        1421112         1076.                 1320\n 2 NORTH GAIA                        1258112         1033.                 1218\n 3 NORTHOAKS                         1268000         1604.                  791\n 4 TENET                             1224000          926.                 1322\n 5 TENET                             1534000         1109.                 1384\n 6 BELLEWATERS                       1745000         1335.                 1307\n 7 THE VISIONAIRE                    1030000          947.                 1087\n 8 THE CANOPY                         970000         1033.                  939\n 9 SKYPARK RESIDENCES                1570000         1302.                 1205\n10 THE BROWNSTONE                    1230000          958                  1284\n# ℹ 3,524 more rows\n# ℹ 17 more variables: `Sale Date` &lt;chr&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\np5 &lt;- ggplot(data=exec_condo, \n       aes(x= `Unit Price ($ PSM)`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\",\n                 fill = \"grey\") +\n  ylab('No. of Transactions') +\n  ggtitle(\"Executive Condominium\")\n\np5"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#conclusion",
    "title": "Take-home Exercise 1 Part 2: DataVis Makeover",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe main flaws of the original histogram is that there are too many colours which are distracting. Stacked histogram also makes it difficult to see the distribution of prices for each property type - for example, detached house and semi-detached house can hardly be seen in the histogram.\nTo improve that, we came up with 3 visualisations:\n\nApartment, Condo, and Terrace House put together in the same plot so that the viewer can compare the distribution of prices between the 3 property types.\nDetached House and Semi-Detached House are put together in the same plot, for the same reason stated above.\nExecutive Condo is on its own, as the range of Unit Price ($ PSM) is different from the other property types.\n\nThis would hopefully make it clearer to the viewer and the colours used are neutral as well, which suits the nature of the data that we are presenting (not trying to show something is good or bad)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will use:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will use:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Visual Statistical Analysis with ggstatsplot",
    "text": "Visual Statistical Analysis with ggstatsplot\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Getting Started",
    "text": "Getting Started\n\n10.3.1 Installing and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\nImporting data\nWe will import the Exam_data.csv file:\n\nexam &lt;- read_csv('data/Exam_data.csv')\n\n\n\nOne-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\nUnpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\nHow to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\nTwo-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\nOneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\nggbetweenstats - Summary of tests\n\n\n\n\n\n\n\n\n\n\nSignificant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\nSignificant Test of Association (Dependence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-models",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Visualising Models",
    "text": "Visualising Models\nIn this section, we will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started-1",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\nImporting Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\nMultiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\nModel Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package is used to check for multicollinearity:\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\nModel Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package is used to check normality assumption:\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\nModel Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package is used to check model for homogeneity of variances:\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\nModel Diagnostic: Complete check\nWe can also perform the complete check by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\nVisualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\nVisualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this hands-on exercise, we will create statistical graphics for visualising uncertainty. We will learn how:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this hands-on exercise, we will create statistical graphics for visualising uncertainty. We will learn how:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\nData import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nNote: Don’t confuse the uncertainty of a point estimate with the variation in the sample.\nIn this section, we will plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, the code chunk below will be used to derive the necessary summary statistics”\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\nNotes:\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is saved as a tibble data table called my_sum.\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\nPlotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\nVisualizing the uncertainty of point estimates with interactive error bars\nIn this section, we will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Visualising Uncertainty: ggdist package",
    "text": "Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package (already done earlier)\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#overview",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#importing-data",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "Importing Data",
    "text": "Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "FunnelPlotR methods",
    "text": "FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\nFunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If City is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\nFunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above:\n\ndata_type argument is used to change from default “SR” to “PR” (i.e. proportions).\nxrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nFunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, we will build funnel plots step-by-step by using ggplot2. It aims to enhance the working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\nComputing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\nCalculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\nPlotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\nInteractive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly R package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#references",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "References",
    "text": "References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "",
    "text": "In this hands-on exercise, we will visualise and analyse text data using R.\nBy the end of this hands-on exercise, you will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "",
    "text": "In this hands-on exercise, we will visualise and analyse text data using R.\nBy the end of this hands-on exercise, you will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and launching R packages\nIn this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\nThe code chunk:\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,\ntidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "Importing Multiple Text Files from Multiple Folders",
    "text": "Importing Multiple Text Files from Multiple Folders\n\nCreating a folder list\n\nnews20 &lt;- \"data/20news/\"\n\n\n\nDefine a function to read all files from a folder into a data frame\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "Importing Multiple Text Files from Multiple Folders",
    "text": "Importing Multiple Text Files from Multiple Folders\n\nReading in all the messages from the 20news folder\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/rds/news20.rds\")\n\nNote:\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "Initial EDA",
    "text": "Initial EDA\nFigure below shows the frequency of messages by newsgroup.\n\nraw_text &lt;- read_rds(\"data/rds/news20.rds\")\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "Introducing tidytext",
    "text": "Introducing tidytext\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\nRemoving header and automated email signitures\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\n\nRemoving lines with nested text representing quotes from other users.\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\n\nText Data Processing\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\nVisualising Words in newsgroups\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\nA DT table can be used to complement the visual discovery.\n\n\nVisualising Words in newsgroups\nThe wordcloud below is plotted by using ggwordcloud package. The code chunk is as follows:\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "Basic Concept of TF-IDF",
    "text": "Basic Concept of TF-IDF\n\ntf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\n\n\nComputing tf-idf within newsgroups\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\n\n\n\nVisualising tf-idf as interactive table\nThe code chunk below uses datatable() of DT package to create a html table that allows pagination of rows and columns.\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\nTo learn more about customising DT’s table, visit this link.\n\n\n\nVisualising tf-idf within newsgroups\nFacet bar charts technique is used to visualise the tf-idf values of science-related newsgroup. The code chunk is:\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\n\n\nCounting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)\n\n\n\nVisualising correlation as a network\nNow, we can visualise the relationship between newgroups in network graph as shown below.\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n\n\n\nBigram\nIn this code chunk below, a bigram data frame is created by using unnest_tokens() of tidytext.\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\n\n\nbigrams\n\n# A tibble: 28,827 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,817 more rows\n\n\n\n\nCounting bigrams\nThe code chunk is used to count and sort the bigram data frame ascendingly.\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\n\nbigrams_count\n\n# A tibble: 19,888 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,878 more rows\n\n\n\n\nCleaning bigram\nThe code chunk below is used to seperate the bigram into two words.\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\n\nbigrams_filtered\n\n# A tibble: 4,607 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,597 more rows\n\n\n\n\nCounting the bigram again\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\n\n\n\nCreate a network graph from bigram data frame\nIn the code chunk below, a network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH f9b7710 DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from f9b7710 (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\nVisualizing a network of bigrams with ggraph\nIn this code chunk below, ggraph package is used to plot the bigram.\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\nRevised version\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "References",
    "text": "References\n\nwidyr\n\nReference guide\n\nwidyr: Widen, process, and re-tidy a dataset\nUnited Nations Voting Correlations"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html",
    "title": "In-class Exercise 5a",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext,\n               quanteda, tidytext)\n\n\ntext_data &lt;- readtext(paste0(\"data/articles\", \"/*\"))\n\n#alternative code: text_data &lt;- readtext(\"data/articles/*\")\n\n\ncorpus_text &lt;- corpus(text_data)\nsummary(corpus_text, 5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n\n\nTokenisation and removing stop words:\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n  !word %in% stop_words$word)\n\nWord count, show in descending order (word with highest count at the top).\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\", \"Y\"),\n                       too_few = \"align_end\")\n\n#separate_wider_delim from tidyr package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html#installing-r-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html#installing-r-packages",
    "title": "In-class Exercise 5a",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext,\n               quanteda, tidytext)\n\n\ntext_data &lt;- readtext(paste0(\"data/articles\", \"/*\"))\n\n#alternative code: text_data &lt;- readtext(\"data/articles/*\")\n\n\ncorpus_text &lt;- corpus(text_data)\nsummary(corpus_text, 5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n\n\nTokenisation and removing stop words:\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n  !word %in% stop_words$word)\n\nWord count, show in descending order (word with highest count at the top).\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\", \"Y\"),\n                       too_few = \"align_end\")\n\n#separate_wider_delim from tidyr package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html",
    "title": "In-class Exercise 6b: MC3 Kick-Starter",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidygraph, ggraph,\n               visNetwork, graphlayouts, ggforce,\n               skimr, tidytext, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#load-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#load-r-packages",
    "title": "In-class Exercise 6b: MC3 Kick-Starter",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidygraph, ggraph,\n               visNetwork, graphlayouts, ggforce,\n               skimr, tidytext, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#load-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#load-data",
    "title": "In-class Exercise 6b: MC3 Kick-Starter",
    "section": "Load Data",
    "text": "Load Data\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json into R environment.\n\nmc3_data &lt;- fromJSON(\"data/MC3.json\")\n\n\nclass(mc3_data)\n\n[1] \"list\"\n\n\nThe output is called mc3_data. It is a large list R object.\n\nExtracting edges\nThe code chunk below extracts the links data.frame of mc3_data and save it as a tibble data.frame called mc3_edges.\n\nmc3_edges &lt;- \n  as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source =\n           as.character(source),\n         target = \n           as.character(target),\n         type =\n           as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n    summarise(weights = n()) %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\n\ndistinct(): to ensure that there are no duplicate records. A record is treated as duplicate if the source and target are the same with another record.\nas.character(source), as.character(target): to avoid potential problems later on, explicitly encode both data types to string/ character data type.\ngroup_by and summarise: to count no. of records between each source and target.\n\n\n\n\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %&gt;%\n  select(id, country, type, revenue_omu, product_services)\n\nWhen we cleaned the nodes data, we removed some of the nodes?? so we have to do this now. left join, so excess ones from mc3_nodes will be left out\n\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\n\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\n\nmc3_nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\nfinally construct graph:\n\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality =\n           centrality_betweenness(),\n         closeness_centrality = \n           centrality_closeness())\n\nBuild graph visualisation:\n\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt;= 300000) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range = c(1,10)) +\n  theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html",
    "title": "In-class Exercise 5b",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html#load-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html#load-packages",
    "title": "In-class Exercise 5b",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html#load-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html#load-data",
    "title": "In-class Exercise 5b",
    "section": "Load data",
    "text": "Load data\nIn the code chunk below, fromJSON() of jsonlite package is used to import the JSON files into R environment:\n\nmc1_data &lt;- fromJSON(\"data/mc1.json\")\n\n\nmc2_data &lt;- fromJSON(\"data/mc2.json\")\n\n\nmc3_data &lt;- fromJSON(\"data/mc3-v1.json\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "The Data",
    "text": "The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges data.\n\nThe edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondences between 55 employees.\n\n\n\nThe nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\nImporting network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\nReviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\nWrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr = FALSE keeps the day spelling in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\nReviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame:\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\nWrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\nReviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges_aggregated data frame\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Creating network objects using tidygraph",
    "text": "Creating network objects using tidygraph\nIn this section, we will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\nThe tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\nThe dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nUsing tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tidygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\nReviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\nReviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 1372 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\nChanging the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html",
    "title": "In-class Exercise 6a",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext, \ncorporaexplorer,\n               quanteda, stringi, rvest, tidytext)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#load-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#load-r-packages",
    "title": "In-class Exercise 6a",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext, \ncorporaexplorer,\n               quanteda, stringi, rvest, tidytext)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#load-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#load-data",
    "title": "In-class Exercise 6a",
    "section": "Load Data",
    "text": "Load Data\nReference: Exploring the King James Bible\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#text-pre-processing",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#text-pre-processing",
    "title": "In-class Exercise 6a",
    "section": "Text Pre-processing",
    "text": "Text Pre-processing\n\n\n\n# Collapsing into one string.\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#metadata",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#metadata",
    "title": "In-class Exercise 6a",
    "section": "Metadata",
    "text": "Metadata\n\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#creating-data-frame-with-text-and-metadata",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#creating-data-frame-with-text-and-metadata",
    "title": "In-class Exercise 6a",
    "section": "Creating data frame with text and metadata",
    "text": "Creating data frame with text and metadata\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#corporaexplorer",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#corporaexplorer",
    "title": "In-class Exercise 6a",
    "section": "corporaexplorer",
    "text": "corporaexplorer\nWhen we first have a data frame with text and metadata, creating a “corporaexplorerobject” for exploration is very simple:\n\nAs this is a corpus which is not organised by date, we set date_based_corpus to FALSE.\nBecause we want to organise our exploration around the books in the Bible, we pass \"Book\" to the grouping_variable argument.\nWe specify which metadata columns we want to be displayed in the “Document information” tab, using the columns_doc_info argument.\n\n\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\nRun corpus explorer:\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Plotting Static Network Graphs with ggraph package",
    "text": "Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each aspect of a network graph, please refer to their respective vignettes provided.\n\nPlotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\nChanging the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\nChanging the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\nWorking with ggraph’s layouts\nggraph support many layouts for standard use, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl.\n\n\nFruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nModifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chunks above, colour and size are used.\n\n\n\n\n\nModifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Creating facet graphs",
    "text": "Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, we will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only drawn in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in all panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\nWorking with facet_edges()\nIn the code chunk below, facet_edges() is used. \n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\nA framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nWorking with facet_nodes()\nIn the code chunk below, facet_nodes() is used.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Network Metrics Analysis",
    "text": "Network Metrics Analysis\n\nComputing centrality indices\nCentrality measures are a collection of statistical indices used to describe the relative importance of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\nVisualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\nVisualising Community\ntidygraph package inherits many of the community detection algorithms embedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "Building Interactive Network Graph with visNetwork",
    "text": "Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\nData preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\nPlotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\nWorking with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\nWorking with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nWorking with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\nInteractivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "The code chunk below loads the necessary R packages for this take-home exercise:\n\npacman::p_load(jsonlite, tidygraph, ggraph,\n               visNetwork, graphlayouts, ggforce,\n               skimr, tidytext, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#getting-started",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "The code chunk below loads the necessary R packages for this take-home exercise:\n\npacman::p_load(jsonlite, tidygraph, ggraph,\n               visNetwork, graphlayouts, ggforce,\n               skimr, tidytext, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-graph-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-graph-data",
    "title": "Take-home Exercise 3",
    "section": "Importing Graph Data",
    "text": "Importing Graph Data\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json into R environment.\n\nmc3_data &lt;- fromJSON(\"data/mc3_cleaned.json\")\n\n\nclass(mc3_data)\n\n[1] \"list\"\n\n\nmc3 data is a directed multigraph with nodes and links. As shown by the output of the code chunk above, they are stored as lists instead of vector columns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-edges",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-edges",
    "title": "Take-home Exercise 3",
    "section": "Wrangling and tidying edges",
    "text": "Wrangling and tidying edges\n\nExtracting edges\nThe code chunk below will be used to extract the links data frame of mc3_data and save it as a tibble data frame called mc3_edges:\n\nmc3_edges &lt;- as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\n\ndistinct() is used to ensure that there will be no duplicated records.\nmutate() and as.character() are used to convert the field data type from list to character.\nthe filter(source != target) is to ensure that no record with similar source and target.\n\n\n\nNext, glimpse() of dplyr will be used to reveal the structure of mc3_edges tibble data frame:\n\nglimpse(mc3_edges)\n\nRows: 75,817\nColumns: 11\n$ start_date          &lt;chr&gt; \"2016-10-29T00:00:00\", \"2035-06-03T00:00:00\", \"202…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the table above, the following data issues can be identified:\n\nstart_date, _last_edited_date, _date_added ,and end_date should be in date data type. Currently they are in character data type.\nSome field names start with “_”, they need to be renamed in order to avoid unnecessary coding issue in the later tasks.\n\n\n\n\n\nCorrecting date data type in mc3_edges\nIn the code chunk below, as_datetime() of lubridate package is used to convert fields with character date into POSIXt format.\n\nmc3_edges$start_date &lt;- as_datetime(mc3_edges$start_date)\nmc3_edges$`_last_edited_date`&lt;- as_datetime(mc3_edges$`_last_edited_date`)\nmc3_edges$`_date_added`&lt;- as_datetime(mc3_edges$`_date_added`)\nmc3_edges$end_date &lt;- as_datetime(mc3_edges$end_date)\n\n\n\nChanging field names in mc3_edges\nIn the code chunk below, rename() of dplyr package is used to change the following fields.\n\nmc3_edges &lt;- mc3_edges %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"date_added\" = \"_date_added\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\")\n\nWe further examine the edges, particularly the type field, and we can see that most of the edges are either Shareholdership or BeneficialOwnership. FamilyRelationship has the least of all.\n\nggplot(data = mc3_edges, aes(x = type)) +\n  geom_bar()\n\n\n\n\nWe remove some columns in mc3_edges that won’t be needed for this analysis:\n\nmc3_edges1 &lt;- subset(mc3_edges, select = -c(last_edited_by, last_edited_date, date_added, raw_source, algorithm, key))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-nodes",
    "title": "Take-home Exercise 3",
    "section": "Wrangling and tidying nodes",
    "text": "Wrangling and tidying nodes\n\nExtracting nodes\nThe code chunk below will be used to extract the nodes data.frame of mc3_data and parses it as a tibble data.frame called mc3_nodes.\n\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  distinct() %&gt;%\n  mutate(country = as.character(country),\n         id = as.character(id), \n         ProductServices = as.character(ProductServices),\n         type = as.character(type))\n\nNext, the code chunk below is used to reveal the data structure of mc3_nodes tibble data.frame.\n\nglimpse(mc3_nodes)\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;chr&gt; \"1954-04-24T00:00:00\", \"2009-06-12T00:00:00\", \"202…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the above output:\n\nfounding_date, _last_edited_date , _date_added , dob should be in the date data type, currently it’s character data type.\nSome field names start with “_”, they need to be renamed in order to avoid unnecessary coding issue in the later tasks.\n\n\n\n\n\nCorrecting date data type in mc3_nodes\nIn the code chunk below, as_datetime() of lubridate package is used to convert fields with character date into POSIXt format.\n\nmc3_nodes$founding_date &lt;- as_datetime(mc3_nodes$founding_date)\nmc3_nodes$`_last_edited_date`&lt;- as_datetime(mc3_nodes$`_last_edited_date`)\nmc3_nodes$`_date_added`&lt;- as_datetime(mc3_nodes$`_date_added`)\nmc3_nodes$dob &lt;- as_datetime(mc3_nodes$dob)\n\n\n\nChanging field names in mc3_nodes\nIn the code chunk below, rename() of dplyr package is used to change the following fields.\n\nmc3_nodes&lt;- mc3_nodes %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"date_added\" = \"_date_added\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\")\n\nFurthermore, in case there are some nodes featured in the edges but not in the nodes from the mc3 list object. For consistency, we will combine both sets of nodes to give the complete nodes df.\n\n# extract all nodes from edges\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\n\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\n\nadditional_nodes &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  filter(!id %in% mc3_nodes[[\"id\"]])\n\n\n#combine all nodes\nmc3_nodes1 &lt;- rbind(mc3_nodes, additional_nodes) %&gt;%\n  distinct()\n\nWe further examine the nodes below, particularly the type field, and we can see that most of the nodes are persons (51,649 nodes):\n\nggplot(data = mc3_nodes1, aes(x = type)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-visualisations",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-visualisations",
    "title": "Take-home Exercise 3",
    "section": "Data Visualisations",
    "text": "Data Visualisations\n\nTask 2 - Atypical Business Transactions\nWe are going to attempt Task 2:\n\n\n\n\n\n\nUsing your visualizations, find and display examples of typical and atypical business transactions (e.g., mergers, acquisitions, etc.). Can you infer the motivations behind changes in their activity?\n\n\n\nFor this task, as we are looking at business transactions such as mergers or acquisitions, etc., we are planning to look at the edges which represent Beneficial Ownership or Shareholdership, and also look into the start_date and end_date to examine which business transactions are typical and atypical. The idea is to visualize the type of event using the weight of the edges, e.g., Beneficial Ownership may have higher weightage than Shareholdership, and hence appear as a thicker line on the network graph. And use the start_date and end_date to see the changes in the network graph over time.\nThe steps are as follows:\n\nIn mc3_edges tibble data frame, include weight factor such that Beneficial Ownership has higher weight than Shareholdership. In particular, Beneficial Ownership, Shareholdership, FamilyRelationship, and Works.For will have weightage of 4, 3, 2, and 1 respectively (assuming this is the level of importance of the types of edges)\nput both edges and nodes together to construct network graph\nBuild graph visualisation\nAdd interactivity (slider) to show changes in network graph over time, using start_date and end_date. Also add tooltip to be able to see entities which are connected to SouthSeafood Express Corp.\n\nStep 1:\n\nIn mc3_edges tibble data frame, include weight factor such that Beneficial Ownership, Shareholdership, FamilyRelationship, and Works.For will have weightage of 4, 3, 2, and 1 respectively.\n\n\nmc3_edges$weight &lt;- ifelse(mc3_edges$type == \"Relationship.FamilyRelationship\", 2, ifelse(mc3_edges$type == \"Event.WorksFor\", 1, \n                                                                                          ifelse(mc3_edges$type == \"Event.Owns.BeneficialOwnership\", 4,\n                                                                                                 ifelse(mc3_edges$type == \"Event.Owns.Shareholdership\", 3, \"Not Applicable\"))))\n\nSince there won’t be any edges that fall under “Not Applicable” weight, we can change data type of the weight factor from character to integer:\n\nmc3_edges$weight &lt;- as.numeric(mc3_edges$weight)\n\nStep 2:\nBefore we put both edges and nodes together to construct network graph, we first need to remove missing values in mc3_edges1:\n\nprint(sum(is.na(mc3_edges1)))\n\n[1] 75559\n\n\nUpon closer observation, it seems that the missing values come from the end_date column. The end_date column contains NA values for Relationship.FamilyRelationship edges, and when the event has not yet ended for Event.Owns.BeneficialOwnership, Event.Owns.Shareholdership, and Event.WorksFor edges.\nTo analyse atypical business transactions, we want to look more closely into transactions where end_date of a transaction may be the same as the start_date of another transaction. Such a transaction looks fishy and may suggest that something illegal is going on. An example is shown below, where AguaLeska Transit N.V. relinquished shareholdership of SouthSeafood Express Corp on the same day that Tainamarine Fishing Co. assumed shareholdership of SouthSeafood Express Corp:\n\nFor the above purpose, we can remove rows where the end_date is NA:\n\nmc3_edges2 &lt;- mc3_edges1[!is.na(mc3_edges1$end_date), ]\n\n#Check for missing values:\nprint(sum(is.na(mc3_edges2)))\n\n[1] 0\n\n\nWe construct the network graph with the code chunk below:\n\nmc3_graph &lt;- tbl_graph(nodes = org_nodes_fishing,\n                       edges = mc3_edges2,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = \n           centrality_betweenness(),\n         closeness_centrality = \n           centrality_closeness())\n\nStep 3:\n\nBuild graph visualisation\n\n\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt;= 300000) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range = c(1,10)) +\n  theme_graph()\n\n\n\nTask 3\nNext, we are going to attempt Task 3:\n\n\n\n\n\n\nDevelop a visual approach to examine inferences. Infer how the influence of a company changes through time. Can you infer ownership or influence that a network may have?\n\n\n\nFor this task, we are planning to use centrality measures such as betweenness centrality and closeness centrality to measure the influence of a company. The higher the betweenness centrality of a company, the more important the company is in acting as a “bridge” to manage relationships and business transactions between other companies, which suggests that this company has high influence over others as it is highly crucial in facilitating flow of information and/or resources between other companies. Similarly, a company with high closeness centrality suggests that this company has high influence as they are close to many other companies and thus, able to efficiently communicate and spread information quickly.\nAt the moment, the idea is to have a visualization that looks like this, where the bigger the size of a node, the higher the betweenness/ closeness centrality of the company (i.e., the more influence a company has), with perhaps a slider to measure any changes in the influential companies over time."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise, we will be able create the following data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise, we will be able create the following data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "Getting Started",
    "text": "Getting Started\nWe install and launch the following R packages:\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nObjectives:\n\nplot a calendar heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, we import eventlog.csv file into R environment and call the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calendar heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBesides extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting.\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Cycle Plot",
    "text": "Plotting Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\nStep 3: Extracting the target country\nNext, the code chunk below is used to extract data for the target country (i.e. Vietnam).\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\nStep 4: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\nStep 5: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Slopegraph",
    "text": "Plotting Slopegraph\nIn this section we will learn how to plot a slopegraph by using R.\nBefore getting started, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\nStep 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\nStep 2: Plotting the slopegraph\nNext, the code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used to convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#check-for-duplicate-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#check-for-duplicate-nodes",
    "title": "Take-home Exercise 3",
    "section": "Check for duplicate nodes",
    "text": "Check for duplicate nodes\nThe output of the code chunk below confirms that there are no duplicated nodes with the same id:\n\nmc3_nodes1[duplicated(mc3_nodes1$id), ] %&gt;%\n  arrange(id)\n\n# A tibble: 0 × 15\n# ℹ 15 variables: type &lt;chr&gt;, country &lt;chr&gt;, ProductServices &lt;chr&gt;,\n#   PointOfContact &lt;chr&gt;, HeadOfOrg &lt;chr&gt;, founding_date &lt;dttm&gt;, revenue &lt;dbl&gt;,\n#   TradeDescription &lt;chr&gt;, last_edited_by &lt;chr&gt;, last_edited_date &lt;dttm&gt;,\n#   date_added &lt;dttm&gt;, raw_source &lt;chr&gt;, algorithm &lt;chr&gt;, id &lt;chr&gt;, dob &lt;dttm&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#cleaning-up-productservices-in-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#cleaning-up-productservices-in-nodes",
    "title": "Take-home Exercise 3",
    "section": "Cleaning up ProductServices in nodes",
    "text": "Cleaning up ProductServices in nodes\nWe note that only nodes of type Organisation have meaningful description for ProductServices, and for nodes of type Person, the ProductServices field has missing values. The same can be said for the following fields: PointOfContact, HeadOfOrg, founding_date, revenue, TradeDescription.\n\nprint(sum(is.na(mc3_nodes1$ProductServices)))\n\n[1] 51649\n\nprint(sum(is.na(mc3_nodes1$PointOfContact)))\n\n[1] 51665\n\nprint(sum(is.na(mc3_nodes1$HeadOfOrg)))\n\n[1] 51649\n\nprint(sum(is.na(mc3_nodes1$founding_date)))\n\n[1] 51649\n\nprint(sum(is.na(mc3_nodes1$revenue)))\n\n[1] 51665\n\nprint(sum(is.na(mc3_nodes1$TradeDescription)))\n\n[1] 51649\n\n\nThe above output also shows that PointOfContact and revenue seems to also be missing for some organisations.\nFor this reason, we will only use the ProductServices column for nodes that are organisations:\n\n# extract type that contains \"Entity.Organization\"\norg_nodes &lt;- mc3_nodes1 %&gt;%\n  filter(str_detect(type, \"Entity.Organization\"))\n\n# extract type that contains \"Entity.Person\"\nperson_nodes &lt;- mc3_nodes1 %&gt;%\n  filter(str_detect(type, \"Entity.Person\"))\n\n# Person_nodes that have meaningful ProductServices\nperson_nodes_w_pdt_services &lt;- person_nodes %&gt;%\n  filter(ProductServices != 'character(0)' & !is.na(ProductServices))\n\nprint(paste0(\"Person nodes with ProductServices not null: \", length(person_nodes_w_pdt_services$id)))\n\n[1] \"Person nodes with ProductServices not null: 0\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#simplifying-productservices-in-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#simplifying-productservices-in-nodes",
    "title": "Take-home Exercise 3",
    "section": "Simplifying ProductServices in nodes",
    "text": "Simplifying ProductServices in nodes\nAs our priority are the fishing-related companies, we will focus on nodes where the type is “Entity.Organization.FishingCompany” (600 nodes).\n\n# simplify ProductServices\norg_nodes_fishing &lt;- org_nodes %&gt;%\n  filter(type == \"Entity.Organization.FishingCompany\")\n\nSince fishing company will not have date of birth (dob), we also remove the dob field from org_nodes_fishing:\n\norg_nodes_fishing &lt;- subset(org_nodes_fishing, select = -dob)\n\n#Check for missing values:\nprint(sum(is.na(org_nodes_fishing)))\n\n[1] 0"
  }
]